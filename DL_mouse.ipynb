{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL mouse.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZBf/F0YikUcVxc2R/Rz+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammadsulton1/ML/blob/main/DL_mouse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9-6XccYaC3z"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/data.zip', 'r') as zip_obj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zip_obj.extractall('data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeLr0UWRbp2h"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn3NhKz4aKvk",
        "outputId": "61d80e23-9b8a-43cc-8a55-5780f97385fa"
      },
      "source": [
        "print('After zip extraction:')\n",
        "print(os.listdir(\"data\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After zip extraction:\n",
            "['data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-cf8b2FdY0g"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net = net.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ivCe6YhdtHE"
      },
      "source": [
        "from torchsummary import summary\n",
        "net = Net()\n",
        "\n",
        "batch = []\n",
        "\n",
        "#batch = batch(next(iter(trainloader)))\n",
        "\n",
        "#summary(net.cuda(), (1,100, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XZAGA79h9G2"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJb8SmmZdzRF",
        "outputId": "f2c79458-d087-40f9-aa24-e733da396830"
      },
      "source": [
        "model = Net()\n",
        "\n",
        "minimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "lr_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer = minimizer, gamma = 0.95)\n",
        "\n",
        "print(\"male weight:\", gender_weights[1])\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss(pos_weight = torch.as_tensor([gender_weights[1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "male weight: 0.5665193370165745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OihbucTLk9Qd"
      },
      "source": [
        "from skimage.transform import resize "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VhsGCVzidzem",
        "outputId": "7dd765a0-64a1-441e-d536-8968efd3179a"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable as var\n",
        "from PIL import Image\n",
        "import scipy.misc\n",
        "import skimage\n",
        "import random\n",
        "\n",
        "image_width = 100\n",
        "image_height = 100\n",
        "\n",
        "np.random.seed(0)\n",
        "    \n",
        "# initialize train data\n",
        "train_data = np.genfromtxt(\"features.csv\", delimiter = ',')\n",
        "np.random.shuffle(train_data) \n",
        "\n",
        "cross_validation_chunks = 10\n",
        "test_chunk = 0\n",
        "\n",
        "test_amount = float(len(train_data)) / cross_validation_chunks\n",
        "train_cv_data = np.concatenate((train_data[:int(test_chunk * test_amount), :], train_data[int((test_chunk + 1) * test_amount):, :]))\n",
        "test_cv_data = train_data[int(test_chunk * test_amount):int((test_chunk + 1) * test_amount)]        \n",
        "\n",
        "class SpectrogramDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, dir, data, augment = False):\n",
        "        self.dir = dir\n",
        "        self.data = data\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        id = self.data[idx, 0]\n",
        "        \n",
        "        fn =  self.dir + \"/\" + \"data\" + (str(int(id)).zfill(9)) + \"r.png\"\n",
        "\n",
        "        gray8 = np.array(Image.open(fn).convert('L'))\n",
        "    \n",
        "        gray8 = gray8.astype(np.float32)\n",
        "\n",
        "        gray8_orig = np.copy(gray8)\n",
        "                \n",
        "        if self.augment:\n",
        "            gray8 /= 255.\n",
        "            max_pad_coeff = 0.1\n",
        "            max_pad = int(gray8.shape[1] * max_pad_coeff)\n",
        "            padded = np.zeros((gray8.shape[0], gray8.shape[1] + 2*max_pad), dtype = gray8.dtype)\n",
        "            # converts to float\n",
        "            padded = skimage.util.random_noise(padded, mode = 'gaussian', var = 0.01)\n",
        "            padded[:, max_pad:(max_pad + gray8.shape[1])] = gray8\n",
        "            gray8 = padded\n",
        "            left = int((random.random() * 1 * max_pad))\n",
        "            right = gray8.shape[1] - int((random.random() * 1 * max_pad))\n",
        "            gray8 = gray8[:, left:right]\n",
        "            # change volume\n",
        "            aug_range = 0.5\n",
        "            rc = 1.0 + aug_range - 2 * aug_range * random.random();            \n",
        "            gray8 *= rc\n",
        "            gray8[gray8 > 1.0] = 1.0\n",
        "            # add noise\n",
        "            # converts to 0..1, float\n",
        "            gray8 = skimage.util.random_noise(gray8, mode = 'gaussian', var = 0.01 * random.random())\n",
        "            gray8[gray8 > 1.0] = 1.0\n",
        "            gray8 *= 255\n",
        "\n",
        "\n",
        "        shape = gray8.shape\n",
        "\n",
        "        max_duration = 100\n",
        "    \n",
        "        resized = np.zeros((233, max_duration), dtype = np.float32)\n",
        "\n",
        "        max_width = min(shape[1], max_duration)\n",
        "\n",
        "        resized[0:233, 0:max_width] = gray8[:, 0:max_width]\n",
        "\n",
        "        # resize rescales the image if it's not uint8!\n",
        "\n",
        "        resized = resized.astype(np.uint8)\n",
        "        #resized = scipy.misc.imresize(resized, (image_height, image_width), interp = 'bilinear')\n",
        "        resized = resize(resized, (image_height, image_width))\n",
        "\n",
        "        resized = resized.astype(np.float32)\n",
        "        \n",
        "        \n",
        "        # test how resulting images look like\n",
        "        if self.augment:\n",
        "        \n",
        "            shape = gray8_orig.shape\n",
        "        \n",
        "            resized_orig = np.zeros((233, max_duration), dtype = np.float32)\n",
        "\n",
        "            max_width = min(shape[1], max_duration)\n",
        "\n",
        "            resized_orig[0:233, 0:max_width] = gray8_orig[:, 0:max_width]\n",
        "\n",
        "            # resize rescales the image if it's not uint8!\n",
        "\n",
        "            resized_orig = resized_orig.astype(np.uint8)\n",
        "            #resized_orig = scipy.misc.imresize(resized_orig, (image_height, image_width), interp = 'bilinear')\n",
        "            resized_orig = resize(resized_orig, (image_height, image_width))\n",
        "\n",
        "            resized_orig = resized_orig.astype(np.float32)\n",
        "        \n",
        "            im = Image.fromarray(resized_orig).convert('L')\n",
        "            im.save(\"data\" + (str(int(id)).zfill(9)) + \"_orig.png\")\n",
        "            im = Image.fromarray(resized).convert('L')\n",
        "            im.save(\"data\" + (str(int(id)).zfill(9)) + \".png\")\n",
        "        \n",
        "        \n",
        "        # hint: do we need to flatten if using pytorch conv2d?\n",
        "        resized = resized.reshape(-1,100,100)\n",
        "        \n",
        "        return (resized, self.data[idx, 2])        \n",
        "\n",
        "\n",
        "\n",
        "dataset = SpectrogramDataset(\"/content/data/data\", train_cv_data, augment = True)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size = 64)\n",
        "test_dataset = SpectrogramDataset(\"/content/data/data\", test_cv_data, augment = False)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 64)\n",
        "\n",
        "\n",
        "gender_weights = []\n",
        "for i in range(2):\n",
        "    gender_weights.append(len(train_cv_data[train_cv_data[:, 2] == i])) \n",
        "    \n",
        "gender_weights = 1.0 / (np.array(gender_weights, dtype = np.float) / len(train_cv_data))\n",
        "gender_weights = gender_weights / np.sum(gender_weights) \n",
        "    \n",
        "print(\"gender weights:\", gender_weights)    \n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      self.conv1 = torch.nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5,padding=2)\n",
        "      self.act1 = torch.nn.ReLU()\n",
        "      self.pool1 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "      self.conv2 = torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,padding=0)\n",
        "      self.act2 = torch.nn.ReLU()\n",
        "      self.pool2 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "\n",
        "      #self.fc1 = torch.nn.Linear(image_width * image_height, 128)\n",
        "      self.fc1 = torch.nn.Linear(16*23*23, 128)\n",
        "      self.bn1 = torch.nn.BatchNorm1d(128)\n",
        "      self.act3 = torch.nn.ReLU()\n",
        "\n",
        "      self.fc2 = torch.nn.Linear(128, 128)      \n",
        "      self.bn2 = torch.nn.BatchNorm1d(128)\n",
        "      self.act4 = torch.nn.ReLU()\n",
        "      self.fc3 = torch.nn.Linear(128, 1) \n",
        "      self.dropout = torch.nn.Dropout(0.3)      \n",
        "\n",
        "      # hint: for conv net use torch.nn.Conv2d\n",
        "      # hint: for conv net use torch.nn.BatchNorm1d(128)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      # hint : add conv layers here\n",
        "      x = self.conv1(x)\n",
        "      x = self.act1(x)\n",
        "      x = self.pool1(x)\n",
        "\n",
        "      x = self.conv2(x)\n",
        "      x = self.act2(x)\n",
        "      x = self.pool2(x)\n",
        "\n",
        "      #print(x.shape) #для определения сколько параметров подавать на вход полносвязной сети\n",
        "      x = x.view(-1,16*23*23)\n",
        "\n",
        "      x = self.fc1(x)\n",
        "      x = self.bn1(x)\n",
        "      #x = torch.nn.functional.relu(x)\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      x = self.fc2(x)\n",
        "      x = self.bn2(x)\n",
        "      #x = torch.nn.functional.relu(x) \n",
        "      x = self.dropout(x)\n",
        "\n",
        "      x = self.fc3(x)\n",
        "\n",
        "      return x      \n",
        "\n",
        "\n",
        "model = Net()\n",
        "\n",
        "#print(model)\n",
        "\n",
        "minimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "lr_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer = minimizer, gamma = 0.95)\n",
        "\n",
        "print(\"male weight:\", gender_weights[1])\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss(pos_weight = torch.as_tensor([gender_weights[1]]))\n",
        "\n",
        "def test_accuracy():\n",
        "\n",
        "    correct_males = 0\n",
        "    correct_females = 0\n",
        "    total_males = 0\n",
        "    total_females = 0\n",
        "\n",
        "    for (test_data_tensor, test_targets_tensor) in test_data_loader:\n",
        "        \n",
        "\n",
        "        out = model(test_data_tensor)\n",
        "        s_out = torch.round(torch.sigmoid(out))\n",
        "        \n",
        "        females = s_out[test_targets_tensor == 0]\n",
        "        correct_females += len(females) - females.sum()\n",
        "        total_females += len(females)\n",
        "\n",
        "        males = s_out[test_targets_tensor == 1]\n",
        "        correct_males += males.sum()\n",
        "        total_males += len(males)\n",
        "\n",
        "    ma = float(correct_males) / total_males\n",
        "    fa = float(correct_females) / total_females\n",
        "    print(\"males accuracy\", ma)        \n",
        "    print(\"females accuracy\", fa)        \n",
        "    print(\"balanced accuracy\", (ma + fa) / 2 )        \n",
        "\n",
        "\n",
        "test_accuracy()\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(int(epochs)):\n",
        "\n",
        "    print(\"training epoch:\", epoch + 1)\n",
        "\n",
        "    for i, (data_tensor, targets_tensor) in enumerate(data_loader):\n",
        "\n",
        "        minimizer.zero_grad()\n",
        "        \n",
        "        # compute prediction for the training data\n",
        "        out = model(data_tensor)\n",
        "                \n",
        "        # compute loss value\n",
        "        loss = criterion(out.squeeze(), targets_tensor)\n",
        "        \n",
        "        # compute the gradient\n",
        "        loss.backward()\n",
        "        \n",
        "        # apply gradient values to the weights\n",
        "        minimizer.step()\n",
        "\n",
        "        accuracies = []\n",
        "\n",
        "    test_accuracy()\n",
        "    \n",
        "  \n",
        "    lr_decay.step()\n",
        "\n",
        "    print(\"loss:\", loss.item())\n",
        "    print(\"learning rate\", minimizer.param_groups[0]['lr'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gender weights: [0.43348066 0.56651934]\n",
            "male weight: 0.5665193370165745\n",
            "males accuracy 0.3863080684596577\n",
            "females accuracy 0.575503355704698\n",
            "balanced accuracy 0.48090571208217786\n",
            "training epoch: 1\n",
            "males accuracy 0.2176039119804401\n",
            "females accuracy 0.9580536912751678\n",
            "balanced accuracy 0.5878288016278039\n",
            "loss: 0.4615191163002963\n",
            "learning rate 0.0095\n",
            "training epoch: 2\n",
            "males accuracy 0.3422982885085575\n",
            "females accuracy 0.9161073825503355\n",
            "balanced accuracy 0.6292028355294466\n",
            "loss: 0.4204768038067066\n",
            "learning rate 0.009025\n",
            "training epoch: 3\n",
            "males accuracy 0.34474327628361856\n",
            "females accuracy 0.9429530201342282\n",
            "balanced accuracy 0.6438481482089233\n",
            "loss: 0.4032488126684846\n",
            "learning rate 0.00857375\n",
            "training epoch: 4\n",
            "males accuracy 0.4669926650366748\n",
            "females accuracy 0.9228187919463087\n",
            "balanced accuracy 0.6949057284914917\n",
            "loss: 0.3649808311817041\n",
            "learning rate 0.0081450625\n",
            "training epoch: 5\n",
            "males accuracy 0.5134474327628362\n",
            "females accuracy 0.8791946308724832\n",
            "balanced accuracy 0.6963210318176597\n",
            "loss: 0.3113212310470232\n",
            "learning rate 0.007737809374999999\n",
            "training epoch: 6\n",
            "males accuracy 0.5965770171149144\n",
            "females accuracy 0.8909395973154363\n",
            "balanced accuracy 0.7437583072151753\n",
            "loss: 0.30867650239105004\n",
            "learning rate 0.007350918906249998\n",
            "training epoch: 7\n",
            "males accuracy 0.6210268948655256\n",
            "females accuracy 0.8976510067114094\n",
            "balanced accuracy 0.7593389507884676\n",
            "loss: 0.29326527743291975\n",
            "learning rate 0.006983372960937498\n",
            "training epoch: 8\n",
            "males accuracy 0.5476772616136919\n",
            "females accuracy 0.9077181208053692\n",
            "balanced accuracy 0.7276976912095305\n",
            "loss: 0.2792673675462926\n",
            "learning rate 0.006634204312890623\n",
            "training epoch: 9\n",
            "males accuracy 0.6234718826405868\n",
            "females accuracy 0.8909395973154363\n",
            "balanced accuracy 0.7572057399780115\n",
            "loss: 0.32031314338500816\n",
            "learning rate 0.006302494097246091\n",
            "training epoch: 10\n",
            "males accuracy 0.5843520782396088\n",
            "females accuracy 0.9026845637583892\n",
            "balanced accuracy 0.7435183209989991\n",
            "loss: 0.29411247541196245\n",
            "learning rate 0.005987369392383786\n",
            "training epoch: 11\n",
            "males accuracy 0.589242053789731\n",
            "females accuracy 0.9110738255033557\n",
            "balanced accuracy 0.7501579396465434\n",
            "loss: 0.3306248153344547\n",
            "learning rate 0.005688000922764597\n",
            "training epoch: 12\n",
            "males accuracy 0.6039119804400978\n",
            "females accuracy 0.912751677852349\n",
            "balanced accuracy 0.7583318291462233\n",
            "loss: 0.2908425324150039\n",
            "learning rate 0.005403600876626367\n",
            "training epoch: 13\n",
            "males accuracy 0.6234718826405868\n",
            "females accuracy 0.9043624161073825\n",
            "balanced accuracy 0.7639171493739847\n",
            "loss: 0.31056801612152485\n",
            "learning rate 0.005133420832795048\n",
            "training epoch: 14\n",
            "males accuracy 0.6430317848410758\n",
            "females accuracy 0.9093959731543624\n",
            "balanced accuracy 0.7762138789977191\n",
            "loss: 0.28524210424852425\n",
            "learning rate 0.0048767497911552955\n",
            "training epoch: 15\n",
            "males accuracy 0.6308068459657702\n",
            "females accuracy 0.8976510067114094\n",
            "balanced accuracy 0.7642289263385897\n",
            "loss: 0.2653179617458301\n",
            "learning rate 0.00463291230159753\n",
            "training epoch: 16\n",
            "males accuracy 0.6528117359413202\n",
            "females accuracy 0.9060402684563759\n",
            "balanced accuracy 0.7794260021988481\n",
            "loss: 0.25484031768725085\n",
            "learning rate 0.0044012666865176535\n",
            "training epoch: 17\n",
            "males accuracy 0.684596577017115\n",
            "females accuracy 0.8976510067114094\n",
            "balanced accuracy 0.7911237918642622\n",
            "loss: 0.20742706239145503\n",
            "learning rate 0.004181203352191771\n",
            "training epoch: 18\n",
            "males accuracy 0.6381418092909535\n",
            "females accuracy 0.9043624161073825\n",
            "balanced accuracy 0.771252112699168\n",
            "loss: 0.2695133470441897\n",
            "learning rate 0.003972143184582182\n",
            "training epoch: 19\n",
            "males accuracy 0.6699266503667481\n",
            "females accuracy 0.8875838926174496\n",
            "balanced accuracy 0.7787552714920989\n",
            "loss: 0.21759471043046283\n",
            "learning rate 0.0037735360253530726\n",
            "training epoch: 20\n",
            "males accuracy 0.6552567237163814\n",
            "females accuracy 0.8993288590604027\n",
            "balanced accuracy 0.777292791388392\n",
            "loss: 0.2760399450508927\n",
            "learning rate 0.0035848592240854188\n",
            "training epoch: 21\n",
            "males accuracy 0.6748166259168704\n",
            "females accuracy 0.8909395973154363\n",
            "balanced accuracy 0.7828781116161534\n",
            "loss: 0.2635456749427782\n",
            "learning rate 0.0034056162628811476\n",
            "training epoch: 22\n",
            "males accuracy 0.6894865525672371\n",
            "females accuracy 0.8791946308724832\n",
            "balanced accuracy 0.7843405917198601\n",
            "loss: 0.18914063456321836\n",
            "learning rate 0.0032353354497370902\n",
            "training epoch: 23\n",
            "males accuracy 0.7017114914425427\n",
            "females accuracy 0.8657718120805369\n",
            "balanced accuracy 0.7837416517615399\n",
            "loss: 0.3906094357638893\n",
            "learning rate 0.0030735686772502355\n",
            "training epoch: 24\n",
            "males accuracy 0.7114914425427873\n",
            "females accuracy 0.889261744966443\n",
            "balanced accuracy 0.8003765937546151\n",
            "loss: 0.3070513086835992\n",
            "learning rate 0.0029198902433877237\n",
            "training epoch: 25\n",
            "males accuracy 0.7114914425427873\n",
            "females accuracy 0.8741610738255033\n",
            "balanced accuracy 0.7928262581841453\n",
            "loss: 0.2927778351533868\n",
            "learning rate 0.0027738957312183374\n",
            "training epoch: 26\n",
            "males accuracy 0.6919315403422983\n",
            "females accuracy 0.8758389261744967\n",
            "balanced accuracy 0.7838852332583974\n",
            "loss: 0.19377629235447602\n",
            "learning rate 0.0026352009446574203\n",
            "training epoch: 27\n",
            "males accuracy 0.7212713936430318\n",
            "females accuracy 0.8456375838926175\n",
            "balanced accuracy 0.7834544887678246\n",
            "loss: 0.1751043053932687\n",
            "learning rate 0.002503440897424549\n",
            "training epoch: 28\n",
            "males accuracy 0.7090464547677262\n",
            "females accuracy 0.8691275167785235\n",
            "balanced accuracy 0.7890869857731249\n",
            "loss: 0.1453737255237099\n",
            "learning rate 0.0023782688525533216\n",
            "training epoch: 29\n",
            "males accuracy 0.7090464547677262\n",
            "females accuracy 0.8741610738255033\n",
            "balanced accuracy 0.7916037642966147\n",
            "loss: 0.16040254684023297\n",
            "learning rate 0.0022593554099256553\n",
            "training epoch: 30\n",
            "males accuracy 0.7481662591687042\n",
            "females accuracy 0.8590604026845637\n",
            "balanced accuracy 0.803613330926634\n",
            "loss: 0.23497962015856805\n",
            "learning rate 0.0021463876394293723\n",
            "training epoch: 31\n",
            "males accuracy 0.7506112469437652\n",
            "females accuracy 0.8523489932885906\n",
            "balanced accuracy 0.8014801201161779\n",
            "loss: 0.16036802643655154\n",
            "learning rate 0.0020390682574579037\n",
            "training epoch: 32\n",
            "males accuracy 0.7481662591687042\n",
            "females accuracy 0.8557046979865772\n",
            "balanced accuracy 0.8019354785776407\n",
            "loss: 0.17325426381391454\n",
            "learning rate 0.0019371148445850085\n",
            "training epoch: 33\n",
            "males accuracy 0.7359413202933985\n",
            "females accuracy 0.8590604026845637\n",
            "balanced accuracy 0.7975008614889811\n",
            "loss: 0.20251364241854858\n",
            "learning rate 0.0018402591023557579\n",
            "training epoch: 34\n",
            "males accuracy 0.7383863080684596\n",
            "females accuracy 0.87248322147651\n",
            "balanced accuracy 0.8054347647724849\n",
            "loss: 0.1819605218030293\n",
            "learning rate 0.0017482461472379698\n",
            "training epoch: 35\n",
            "males accuracy 0.7237163814180929\n",
            "females accuracy 0.87751677852349\n",
            "balanced accuracy 0.8006165799707914\n",
            "loss: 0.22023340398013508\n",
            "learning rate 0.0016608338398760713\n",
            "training epoch: 36\n",
            "males accuracy 0.7212713936430318\n",
            "females accuracy 0.8808724832214765\n",
            "balanced accuracy 0.8010719384322542\n",
            "loss: 0.17365204614584456\n",
            "learning rate 0.0015777921478822676\n",
            "training epoch: 37\n",
            "males accuracy 0.7286063569682152\n",
            "females accuracy 0.8624161073825504\n",
            "balanced accuracy 0.7955112321753828\n",
            "loss: 0.22383901769244152\n",
            "learning rate 0.001498902540488154\n",
            "training epoch: 38\n",
            "males accuracy 0.7506112469437652\n",
            "females accuracy 0.8523489932885906\n",
            "balanced accuracy 0.8014801201161779\n",
            "loss: 0.17155304390251955\n",
            "learning rate 0.0014239574134637463\n",
            "training epoch: 39\n",
            "males accuracy 0.7237163814180929\n",
            "females accuracy 0.8708053691275168\n",
            "balanced accuracy 0.7972608752728049\n",
            "loss: 0.1859094318782499\n",
            "learning rate 0.0013527595427905588\n",
            "training epoch: 40\n",
            "males accuracy 0.7310513447432763\n",
            "females accuracy 0.8741610738255033\n",
            "balanced accuracy 0.8026062092843897\n",
            "loss: 0.14084783929031258\n",
            "learning rate 0.0012851215656510308\n",
            "training epoch: 41\n",
            "males accuracy 0.7090464547677262\n",
            "females accuracy 0.8859060402684564\n",
            "balanced accuracy 0.7974762475180913\n",
            "loss: 0.1931059696019746\n",
            "learning rate 0.0012208654873684791\n",
            "training epoch: 42\n",
            "males accuracy 0.726161369193154\n",
            "females accuracy 0.8808724832214765\n",
            "balanced accuracy 0.8035169262073152\n",
            "loss: 0.24153372189665312\n",
            "learning rate 0.0011598222130000551\n",
            "training epoch: 43\n",
            "males accuracy 0.7334963325183375\n",
            "females accuracy 0.860738255033557\n",
            "balanced accuracy 0.7971172937759472\n",
            "loss: 0.16291749225756463\n",
            "learning rate 0.0011018311023500522\n",
            "training epoch: 44\n",
            "males accuracy 0.7408312958435208\n",
            "females accuracy 0.8657718120805369\n",
            "balanced accuracy 0.8033015539620288\n",
            "loss: 0.17203601071126756\n",
            "learning rate 0.0010467395472325495\n",
            "training epoch: 45\n",
            "males accuracy 0.706601466992665\n",
            "females accuracy 0.8708053691275168\n",
            "balanced accuracy 0.7887034180600909\n",
            "loss: 0.25455603704636454\n",
            "learning rate 0.000994402569870922\n",
            "training epoch: 46\n",
            "males accuracy 0.7432762836185819\n",
            "females accuracy 0.87248322147651\n",
            "balanced accuracy 0.807879752547546\n",
            "loss: 0.18121075857090035\n",
            "learning rate 0.0009446824413773759\n",
            "training epoch: 47\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-6f195b47be67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mminimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-6f195b47be67>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# add noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# converts to 0..1, float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mgray8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mgray8\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgray8\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mgray8\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/util/noise.py\u001b[0m in \u001b[0;36mrandom_noise\u001b[0;34m(image, mode, seed, clip, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         noise = np.random.normal(kwargs['mean'], kwargs['var'] ** 0.5,\n\u001b[0;32m--> 133\u001b[0;31m                                  image.shape)\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5o74Uk_pfCu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}